"""Multi-Label Image Classification using PyTorch.

Models for images with multiple labels simultaneously.
Uses BCE loss and sigmoid activation.
"""

import warnings

warnings.filterwarnings("ignore")


def train():
    print("=== Multi-Label Image Classification (PyTorch) ===\n")

    # 1. Multi-Label Classification Basics
    print("1. Multi-Label Classification Overview...")

    print("\nKey Differences from Single-Label:")
    print("  - Multiple classes per image (e.g., cat AND dog)")
    print("  - Binary Cross-Entropy (BCE) loss instead of CE")
    print("  - Sigmoid activation instead of Softmax")
    print("  - Independent probability per class")
    print("  - Threshold-based prediction (usually 0.5)")

    print("\nExample Use Cases:")
    print("  - Image tagging: beach, sunset, ocean, sky")
    print("  - Medical imaging: multiple diseases detected")
    print("  - Object detection: multiple objects in scene")
    print("  - Document classification: multiple topics")

    # 2. Multi-Label Model Implementation
    print("\n2. Multi-Label ResNet Implementation...")
    try:
        import torch
        import torch.nn as nn
        import torchvision.models as models
        import torchvision.transforms as transforms
        from torch.utils.data import Dataset, DataLoader
        import numpy as np

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Using device: {device}")

        # Custom multi-label dataset
        class MultiLabelDataset(Dataset):
            def __init__(self, num_samples=1000, num_classes=5):
                self.num_samples = num_samples
                self.num_classes = num_classes

                # Generate random images
                self.images = torch.randn(num_samples, 3, 224, 224)

                # Generate random multi-labels (0 or 1 for each class)
                self.labels = torch.randint(0, 2, (num_samples, num_classes)).float()

            def __len__(self):
                return self.num_samples

            def __getitem__(self, idx):
                return self.images[idx], self.labels[idx]

        # Create dataset
        print("Creating multi-label dataset...")
        train_dataset = MultiLabelDataset(num_samples=800, num_classes=5)
        test_dataset = MultiLabelDataset(num_samples=200, num_classes=5)

        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

        print(f"âœ“ Train samples: {len(train_dataset)}")
        print(f"âœ“ Test samples: {len(test_dataset)}")
        print(f"âœ“ Number of classes: 5")

        # Load ResNet and modify for multi-label
        print("\nBuilding multi-label model...")
        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)

        # Replace final layer - NO SOFTMAX!
        num_features = model.fc.in_features
        model.fc = nn.Linear(num_features, 5)  # 5 classes

        model = model.to(device)
        print(f"âœ“ Model parameters: {sum(p.numel() for p in model.parameters()):,}")

        # Multi-label loss: Binary Cross Entropy
        criterion = nn.BCEWithLogitsLoss()  # Includes sigmoid

        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

        # Train
        print("\nTraining for 2 epochs...")
        num_epochs = 2

        for epoch in range(num_epochs):
            model.train()
            train_loss = 0.0

            for batch_idx, (inputs, targets) in enumerate(train_loader):
                inputs, targets = inputs.to(device), targets.to(device)

                optimizer.zero_grad()
                outputs = model(inputs)  # Raw logits
                loss = criterion(outputs, targets)
                loss.backward()
                optimizer.step()

                train_loss += loss.item()

                if batch_idx % 10 == 0:
                    print(f"Epoch {epoch+1}/{num_epochs} | "
                          f"Batch {batch_idx}/{len(train_loader)} | "
                          f"Loss: {loss.item():.4f}")

            avg_loss = train_loss / len(train_loader)
            print(f"Epoch {epoch+1} Average Loss: {avg_loss:.4f}\n")

        print("âœ“ Multi-label training completed")

        # 3. Prediction and Evaluation
        print("\n3. Multi-Label Prediction...")

        model.eval()
        with torch.no_grad():
            # Get first test batch
            inputs, targets = next(iter(test_loader))
            inputs = inputs.to(device)

            # Get predictions
            outputs = model(inputs)

            # Apply sigmoid to get probabilities
            probs = torch.sigmoid(outputs)

            # Apply threshold (0.5)
            predictions = (probs > 0.5).float()

            # Show first example
            print("Example prediction:")
            print(f"  True labels: {targets[0].numpy()}")
            print(f"  Probabilities: {probs[0].cpu().numpy()}")
            print(f"  Predictions: {predictions[0].cpu().numpy()}")

        print("âœ“ Multi-label prediction demonstrated")

    except Exception as e:
        print(f"Error: {e}")

    # 4. Multi-Label Metrics
    print("\n4. Multi-Label Evaluation Metrics...")

    metrics_code = """
from sklearn.metrics import (
    hamming_loss, accuracy_score, f1_score,
    precision_score, recall_score, jaccard_score
)

# Collect predictions
y_true = []
y_pred = []

model.eval()
with torch.no_grad():
    for inputs, targets in test_loader:
        inputs = inputs.to(device)
        outputs = model(inputs)
        probs = torch.sigmoid(outputs)
        preds = (probs > 0.5).float()

        y_true.extend(targets.cpu().numpy())
        y_pred.extend(preds.cpu().numpy())

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Calculate metrics
hamming = hamming_loss(y_true, y_pred)
subset_acc = accuracy_score(y_true, y_pred)  # Exact match
micro_f1 = f1_score(y_true, y_pred, average='micro')
macro_f1 = f1_score(y_true, y_pred, average='macro')
samples_f1 = f1_score(y_true, y_pred, average='samples')

print(f"Hamming Loss: {hamming:.4f}")  # Lower is better
print(f"Subset Accuracy: {subset_acc:.4f}")  # Exact match rate
print(f"Micro F1: {micro_f1:.4f}")
print(f"Macro F1: {macro_f1:.4f}")
print(f"Samples F1: {samples_f1:.4f}")

# Per-class metrics
for i in range(num_classes):
    precision = precision_score(y_true[:, i], y_pred[:, i])
    recall = recall_score(y_true[:, i], y_pred[:, i])
    f1 = f1_score(y_true[:, i], y_pred[:, i])
    print(f"Class {i}: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f}")
"""
    print(metrics_code)

    # 5. Advanced Techniques
    print("\n5. Advanced Multi-Label Techniques...")

    print("\nğŸ¯ Class Balancing with Weighted Loss:")
    weighted_code = """
# Calculate class frequencies
class_counts = targets.sum(dim=0)
total = targets.shape[0]
class_weights = total / (class_counts * num_classes)

# Use weighted BCE loss
pos_weight = class_weights.to(device)
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
"""
    print(weighted_code)

    print("\nğŸ”§ Focal Loss for Hard Examples:")
    focal_code = """
class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, inputs, targets):
        bce_loss = F.binary_cross_entropy_with_logits(
            inputs, targets, reduction='none'
        )
        pt = torch.exp(-bce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss
        return focal_loss.mean()

criterion = FocalLoss()
"""
    print(focal_code)

    print("\nğŸ“Š Dynamic Threshold Selection:")
    threshold_code = """
# Instead of fixed 0.5, optimize threshold per class
from sklearn.metrics import f1_score

def find_optimal_thresholds(y_true, y_scores):
    thresholds = []
    for i in range(y_true.shape[1]):
        best_threshold = 0.5
        best_f1 = 0

        for threshold in np.arange(0.1, 0.9, 0.1):
            preds = (y_scores[:, i] > threshold).astype(int)
            f1 = f1_score(y_true[:, i], preds)

            if f1 > best_f1:
                best_f1 = f1
                best_threshold = threshold

        thresholds.append(best_threshold)

    return np.array(thresholds)

# Use optimized thresholds
thresholds = find_optimal_thresholds(val_true, val_scores)
predictions = (test_scores > thresholds).astype(int)
"""
    print(threshold_code)

    print("\nğŸ—ï¸ Label Correlation:")
    correlation_code = """
# Some labels co-occur frequently (e.g., beach + ocean)
# Use label correlation in model

class LabelCorrelationModel(nn.Module):
    def __init__(self, base_model, num_classes):
        super().__init__()
        self.base_model = base_model

        # Additional layer to capture label dependencies
        self.label_correlation = nn.Linear(num_classes, num_classes)

    def forward(self, x):
        # Get base predictions
        base_out = self.base_model(x)

        # Apply label correlation
        corr_out = self.label_correlation(torch.sigmoid(base_out))

        return base_out + corr_out

model = LabelCorrelationModel(resnet, num_classes=10)
"""
    print(correlation_code)

    # 6. Real-World Applications
    print("\n6. Real-World Multi-Label Applications...")

    applications = {
        "Image Tagging": {
            "example": "beach, sunset, ocean, people",
            "classes": "100-1000",
            "challenge": "Long-tail distribution"
        },
        "Medical Diagnosis": {
            "example": "pneumonia, effusion, cardiomegaly",
            "classes": "10-50",
            "challenge": "Class imbalance, rare diseases"
        },
        "Video Analysis": {
            "example": "action1, action2, object1, scene",
            "classes": "50-500",
            "challenge": "Temporal consistency"
        },
        "Document Classification": {
            "example": "sports, politics, technology",
            "classes": "20-100",
            "challenge": "Hierarchical labels"
        }
    }

    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚     Application       â”‚          Example          â”‚  Classes   â”‚        Challenge         â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

    for app, info in applications.items():
        print(f"â”‚ {app:21} â”‚ {info['example']:25} â”‚ "
              f"{info['classes']:10} â”‚ {info['challenge']:24} â”‚")

    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    # QA Validation
    print("\n=== QA Validation ===")
    print("âœ“ Multi-label basics explained")
    print("âœ“ Multi-label model implemented")
    print("âœ“ BCE loss demonstrated")
    print("âœ“ Multi-label metrics shown")
    print("âœ“ Advanced techniques covered")
    print("âœ“ Real-world applications listed")

    print("\n=== Summary ===")
    print("Multi-Label Classification:")
    print("- Use BCEWithLogitsLoss instead of CrossEntropy")
    print("- Apply Sigmoid instead of Softmax")
    print("- Each class is independent prediction")
    print("- Threshold typically 0.5 (but can be optimized)")
    print("\nKey Metrics:")
    print("- Hamming Loss: Fraction of wrong labels")
    print("- Subset Accuracy: Exact match rate")
    print("- Micro/Macro F1: Different averaging strategies")
    print("- Per-class metrics: Important for imbalanced data")
    print("\nBest Practices:")
    print("- Handle class imbalance with weighted loss")
    print("- Optimize thresholds per class on validation set")
    print("- Consider label correlations")
    print("- Use appropriate evaluation metrics")

    return {
        "task": "multi-label classification",
        "loss": "BCEWithLogitsLoss",
        "activation": "Sigmoid",
        "metrics": ["hamming_loss", "subset_accuracy", "f1_score"]
    }


if __name__ == "__main__":
    train()
